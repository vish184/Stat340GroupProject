---
title: "Final Project"
output:
  pdf_document: default
  html_document: default
---

```{R setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
```

The following block reads in the data sets containing player statistics and salaries for the 2019-2020 and 2020-2021 seasons. It also changes a few variable names to ensure they match for the join.

```{R}
player_stats_2019_20 <- read.csv("2019-20_player_stats.csv")
player_salaries_2019_20 <- read.csv("2019-20_player_salaries.csv")
#player_stats_2019_20
colnames(player_salaries_2019_20)[3] <- "Player"
#player_salaries_2019_20

player_stats_2020_21 <- read.csv("2020-21_player_stats.csv")
player_salaries_2020_21 <- read.csv("2020-21_player_salaries.csv")
#player_stats_2020_21
colnames(player_salaries_2020_21)[3] <- "salary"
#player_salaries_2020_21
```

The following code joins the player statistics and player salary data sets into one data frame by different years. It also removes the cases where players were traded in the middle of the season to prevent any duplicate salary information from being included.

```{R}
merged_2019_20 <- merge(player_salaries_2019_20, player_stats_2019_20, by = 'Player')
merged_2019_20 <- merged_2019_20 %>%
  distinct(Player, .keep_all = TRUE)

merged_2020_21 <- merge(player_salaries_2020_21, player_stats_2020_21, by = 'Player')
merged_2020_21 <- merged_2020_21 %>%
  distinct(Player, .keep_all = TRUE)
  
```

The following code divides our tables into 3 different sets. We will train our multiple-regression model on the 2019-2020 season. The train data frame will additionally be divided into a dev data frame to compare with our test data frame to make sure our multiple-regression model remains consistent over different data frames. We also end up using the 2020-2021 season as our test data frame.

```{R}
data_split <- sort(sample(nrow(merged_2019_20), nrow(merged_2019_20)*0.8))
train <- merged_2019_20[data_split,]
dev <- merged_2019_20[-data_split,]
test <- merged_2020_21
```

Here we create our multiple-regression model.

```{R}
model <- lm(salary ~ 1 + Age + G + GS + BLK + TOV + PF + PTS, train)
summary(model)
```

Based on the variables provided on the players, without using their names, we are able to achieve an R-squared value of **0.5622**. The most important variables are "Age", "PTS", and "G". This makes sense as younger players lack experience that would make them more valuable to the team and older players are more likely to have a harder time keeping up with the speed of the game. As for points, it is pretty self explanatory as players who score more points are more valuable to their team. Additionally, games played is important because a team does not want to pay a player that doesn't play.

As the primary goal of this model is to predict the salary variable, we can use the R-squared statistic to analyze how good the model. It is clear that a R-squared of **0.5622** is not very good. In addition, if we look at the model diagnostics, it becomes pretty clear that our current model is not very good. The first one we will look at is the Residual vs Fitted plot. 

```{r}
plot(model, which = 1)
```

You can see that there is a "funneling" effect on the graph. The distribution of the residuals is concentrated around 0 for small fitted values, but they get more and more spread out as the fitted values increase. This phenomena is called increasing variance. And, the Scale-Location graph also confirms this below. 

```{r}
plot(model, which = 3)
```

There is a clear upward trend in the red line which reaffirms our previous statement that the model has non-constant variance. One more thing that we should look at is the Normal QQ plot which lets us assess whether the residuals are normally distributed. 

```{r}
plot(model, which = 2)
```

We observe heavier tails in this graph which tells us that tge model has larger values that we would expect under the standard modeling assumptions. But, it looks like normality assumption is still valid. 

It is now clear that our model is not very good, so we have to resort to other methods. Our orignial plan was to use ridge regression to achieve a better model but an assumption of ridge regression is constant variance so we cannot use it. Lasso regression also has the same assumptions so we cannot use that one either. We had to resort to some online reserach and we found a method to acheive a lienar model with non-constant variances. We found out that the technical term for non-constant variance is heteroskedasticity. We found a good resource to solve this problem and I have provided the link below:
http://bkenkel.com/psci8357/notes/05-ncv.html

The resource tells us that in order to solve heteroskedasticity of an unknown form we can use something called Whiteâ€™s heteroskedasticity-consistent estimator which is what we did below

```{r}
library(car)
library(lmtest)
vcv0 <- hccm(model, type = "hc0")
vcv0

library("broom")
modelv2 <- tidy(coeftest(model, vcov = vcv0))

```
This model know has accounted for the heteroskedacticity and we can now perform the predictions in the model. 


Now we will predict on our dev data frame and test data frame.

```{R}
dev_predictions <- predict(model, newdata = dev)
test_predictions <- predict(model, newdata = test)
```


